


\section{Systemabläufe}
Im Kapitel Anforderungen wurden die Anforderungen gesammelt und später in einen Anwendungsfalldiagramm logisch gruppiert |anmerkung, damit meine ich das Use-Case Diagram. Am liebsten würde ich das aber weglassen(ist sowieso noch nicht fertig) und die logische Gruppierung lieber hier beginnen|. Anwendungsfalldiagramme haben dabei die Aufgabe, die beabsichtigte Funktionalität eines Systems zu veranschaulichen, ohne in die technischen Details seiner Umsetzung einzutauchen (vgl. \cite{Siau2002-ww},S. 372)
Der vorliegenden Abschnitts zielt deswegen darauf ab, den komplexeren Systemabläufen eine erste grobe Struktur in der Konzeptionsphase zu verleihen und gleichzeitig die erste potentiellen Schwierigkeiten hervorzuheben. Basierend auf das gesammelten Wissen, soll dann die weitere Konzeptionsphase darauf aufbauen.



\subsubsection{Erstellung von Geräten}
\label{device_creation}
Der erste Anwendungsfall beschäftigt sich mit der Erstellung von Geräten und umfasst dabei die Anforderungen \ref{12},\ref{13},\ref{15}. Die grobe Struktur kann dabei der Abbildung \ref{fig:createdevice} entnommen werden.
Ziel der Erstellung ist dabei den Nutzer die Möglichkeit zu geben ein Gerät zu erstellen, welches alle benötigten Informationen besitzt, um als valide zu gelten. Dazu gehören ein Name, eine IP-Adresse sowie Kostenplan als auch RPU-Capabilities. Während die Erstellung eines Geräts noch keine Schwierigkeit darstellt, ergibt sich jedoch bei der Übertragung der Konfiguration vom Query-Repository zum Optimierer die Frage, mit welcher Technologie die Daten übertragen werden und welche Struktur die zu versendende Nachricht haben muss, um von beiden Systemkomponenten verarbeitet werden zu können.

\begin{figure}[h!]
	\centering
	\includegraphics[width=0.8\linewidth]{"../../OneDrive/masterarbeit/Analyse Kapitel/create_device.drawio"}
	\caption{}
	\label{fig:createdevice}
\end{figure}


\subsubsection{Modifizierung von Geräten}
Der zweite Anwendungsfall, das aktualisieren von Geräten, umfasst die Anforderungen \ref{14}, \ref{16}, \ref{17}, \ref{18}, \ref{19} und \ref{20}. Die grobe Struktur kann dabei der Abbildung \ref{fig:changedeviceconfig} entnommen werden.
Wie im Ablauf zu sehen ist, soll Nutzer eine Liste aller Geräte sehen können und sich anschließend dazu entscheiden ein Gerät auszuwählen. Anschließend hat er die Möglichkeit unterschiedlichen Eigenschaften des Geräts zu modifizieren. Dabei ist wichtig, dass er die Möglichkeit auch besitzt, alle versionierten Kostenpläne bzw. RPU-Capabilities als Auswahl nutzen zu können. Im Query-Repository muss dann für Kostenplan als auch RPU-Capabilities geprüft werden, ob diese sich verändert haben und sofern dies der Fall ist, müssen diese versioniert werden. 
Abgesehen von den Schwierigkeiten, wie sie auch schon bei der Erstellung beschrieben wurden, stellt sich die Frage, ob bereits versionierte Kostenpläne bzw. RPU-Capabilities erneut versioniert werden. Die größere Schwierigkeit ist jedoch Inkonsistenzen möglichst zu vermeiden, die aufgrund von Latenzen in der Übertragung als auch in der Verarbeitung im Optimierer entstehen können. Für den Prototypen soll jedoch darauf hingewiesen werden, dass davon ausgegangen werden darf, dass die Nachricht sofort ankommt und verarbeitet wird. Um Inkonsistenzen jedoch zu vermeiden, könnte in Zukunft die Anforderung \ref{212} aufgenommen werden in den Ablauf.


\begin{figure}[h!]
	\centering
	\includegraphics[width=0.9\linewidth]{"../../OneDrive/masterarbeit/Analyse Kapitel/change_device_config.drawio"}
	\caption{}
	\label{fig:changedeviceconfig}
\end{figure}

\newpage


\subsubsection{Datenbankabfrage und Ausführungsplan}
\label{Datenbankabfrage und Ausführungsplan}
Ein besonders essentieller Anwendungsfall besteht aus den Anforderungen \ref{1}, \ref{2}, \ref{111} und \ref{112}.
Der Systemablauf kann in Abbildung \ref{fig:receivestorequeryexe} gesehen werden.
Der Ablauf macht deutlich, dass in einer Nachricht vom Optimierer immer eine  Datenbankabfrage und den dazugehörigen Ausführungsplan enthält. Da beide Entitäten gleichzeitig ankommen, ist das speichern dieser beiden einfach umzusetzen.
Offen gehalten wird noch, wie die dazugehörigen Kostenmodelle als auch RPU Capabilities, die zu dem Ausführungsplan geführt haben, abgespeichert werden. Diese Problemstellung kann erst dann gelöst werden, wenn klar wird, wie die unterschiedlichen Entitäten in der Datenbank abgespeichert werden. 
\begin{figure}[h!]
	\centering
	\includegraphics[width=0.7\linewidth]{"../../OneDrive/masterarbeit/Analyse Kapitel/receive_store_query_exe.drawio"}
	\caption{Systemablauf beim Empfang einer Datenbankabfrage und des dazugehörigen Ausführungsplans}
	\label{fig:receivestorequeryexe}
\end{figure}
\newpage
\subsubsection{Verlaufshistorie Datenbankabfragen}\label{verlauf}
Der Anwendungsfall, der die Anforderungen \ref{3}, \ref{4}, \ref{5}, \ref{9} und \ref{90} vereint, kann in Abbildung \ref{fig:query-history} gesehen werden. Wie die Abbildung zeigt, soll der Nutzer dabei die Datenbankabfragen nach bestimmten Daten filtern können und anschließend eine Datenbankabfrage aussuchen, für die er den Kostenplan anschauen möchte. Als zukünftige weitere Anforderung könnte die Anforderung 26 aufgenommen werden die es ermöglichen sollen, dass in Echtzeit neu gespeicherte Datenbankabfragen nachgeladen werden.





\begin{figure}[h!]
	\centering
	\includegraphics[width=0.5\linewidth]{"../../OneDrive/masterarbeit/Analyse Kapitel/query-history.drawio"}
	\caption{Die Aktivitäten eines Nutzers, der zu einer Datenbankabfrage die Ausführungspläne erhalten möchte}
	\label{fig:query-history}
\end{figure}

\newpage
\subsubsection{Datenbankabfrage Analyse} \label{Datenbankabfrage_Analyse}
Wie in \nameref{verlauf} erwähnt, kann der Systemablauf, der die Anforderungen \ref{10} und \ref{11} widerspiegelt, als eine Erweiterung angesehen werden.
Auch wenn dieser Ablauf nur zwei weitere Anforderungen umsetzten wird, wird er als eigener Systemablauf aufgeführt.
Grund dafür ist die voraussichtliche Komplexität bzw. Vorarbeit, die der Ablauf nötig ist. 
Einerseits muss es vorher möglich sein Geräte zu erstellen aufgrund der benötigten Kostenpläne und RPU Capabilities. 
Zusätzlich muss ebenfalls geklärt werden, wie die Informationen RPU Capabilities, Kostenmodelle, Ausführungsplan sowie Datenbankabfrage abgespeichert werden.
Abschließend kann dann der Systemablauf in Abbildung \ref{fig:query-history} erweitert, um zusätzlich eine Analyse von Datenbankabfragen zu ermöglichen. 

\begin{figure}[h!]
	\centering
	\includegraphics[width=0.5\linewidth]{"../../OneDrive/masterarbeit/Analyse Kapitel/query_analysis.drawio"}
	\caption{}
	\label{fig:queryanalysis}
\end{figure}
\newpage



\subsubsection{Datenbankabfrage Ausführung}
Anforderungen \ref{6}, \ref{7},\ref{8} bilden den Anwendungsfall ab welcher die Ausführung einer Datenbankabfrage mit anschließender Ausgabe des Ausführungsplan darstellt. Wie der Ablauf im speziellen aussieht, kann in der Abbildung \ref{fig:queryexecution2} gesehen werden. Schnell wird deutlich, dass dieser Systemablauf mit den meisten externen Aktoren interagiert. Die empfangene Datenbankabfrage vom Nutzer wird dabei weitergeleitet zum Gateway. Dies ist, wie auch in Anforderungen beschrieben, vorgeschrieben.
In Anschluss wird der Systemablauf durchlaufen, der für den Erhalt von Nachrichten des Optimierers geplant ist und in Abbildung \ref{fig:receivestorequeryexe} nachgeschlagen werden kann. 
Dadurch, dass das Query-Repository nicht mit dem Optimierer direkt kommuniziert, sondern nur Datenbankabfragen und Ausführungspläne erhält, wird voraussichtlich das Query-Repository in der Datenbank darauf warten müssen, dass ein zeitlich passender Ausführungsplan zu der Datenbankabfrage in der Datenbank gespeichert wurde.
\begin{figure}[h!]
	\centering
	\includegraphics[width=0.9\linewidth]{"../../OneDrive/masterarbeit/Analyse Kapitel/query_execution2.drawio"}
	\caption{}
	\label{fig:queryexecution2}
\end{figure}

\newpage











\section{Datenmodell}\label{sec:Datenmodell}

Das Datenmodell ist die Grundlage das Query-Repository,da die überwiegende Aufgabe des Systems ist Daten abzuspeichern und diese einen Nutzer später zusammenhängend wiederzugeben sowie das Konfigurieren von Geräten.
Wie das Datenmodell jedoch ausschaut, wird stark von der Datenbanktechnologie abhängig. Während im NoSQL Fall der Großteil der Daten in einfachen Dokumenten gespeichert werden würde und damit die Datenmodellierung eher wenig Freiraum besitzen würde. Im relationalen Fall hingegen müsste sich Gedanken über die Entitäten als auch deren Relationen untereinander gemacht werden, da hier prinzipiell viele unterschiedliche Möglichkeiten bieten würden ein Datenmodell zu entwerfen wohingegen unterschiedliche Datenmodelle unterschiedliche Einflüsse in die Performance (TODO ggf. nach Quelle suchen die sich damit beschäftigt hat) als auch später in der logischen Kommunikation der Komponent untereinander haben wird.
Das Kapitel daher so aufgebaut, dass im ersten Schritt eine Diskussion und Analyse über das Datenmodell geführt wird und sich für eine Datenbanktechnologie entschieden wird.
Im Anschluss wird dann in weiteren Unterkapiteln die Entitäten und deren Relationen genauer diskutiert in den Vorschläge für deren Datenmodellen gemacht und diskutiert werden.



\subsection{Analyse und Technologieauswahl für die Speicherung der Daten}
Anhand des Technologiekapitels wurde ersichtlich, dass es Unterscheidungen zwischen dokumentenorientierten und relationalen Datenbank gibt.
Weiterhin hat sich jedoch gezeigt, dass die unterstützen Funktionalitäten beider Technologie in laufe der Jahren immer näher rücken(todo zeigen wann die features eingefügt wurden, also mit welchen Version).
Da wo relationale Datenbanken Joins nutzen, können dokumentenorientierten Datenbanken wie mongodb lookup nutzen und während mongoDB alles in JSONB abspeichert, bieten gängige relationale Datenbanken ebenfalls JSON oder JSONB als Datentypen an. Aufgrund dessen kann prinzipiell daraus geschlossen werden, dass die Anwendung sowohl mittels einer dokumentenorientierten Datenbank als auch einer relationalen Datenbank erstellt werden kann. 




Um  trotzdem eine fundierte Entscheidung treffen zu können, soll im folgenden die Entitäten vorgestellt werden, die in der Datenbank abgespeichert werden müssen:
\begin{itemize}
	\item \textbf{Device} \newline
	Für das Projekt ist es nötig unterschiedliche Geräte konfigurieren zu können. Ein Gerät besitzt dabei einerseits einen Namen für die leichtere Identifizierbarkeit, eine IP Adresse und kann mehrere Ports besitzen. Ein Port kann dabei entweder auf einen Datenstream verweisen oder 
	
	
	 wobei ein Port eine Beschreibung besitzt und ebenfalls eine Verbindung zu einem Datastream besitzt kann. Zusätzlich besitzt ein Gerät ebenfalls Geräteeigenschaften sowie ein Kostenmodell
	\item \textbf{Datastream} \newline
	Ein Datenstream besitzt ein bestimmtes Schema. Dieses Schema muss bekannt sein damit ein Gerät so konfiguriert werden kann, dass es den Datastream später verarbeiten kann. Für die Anwendung ist dabei die Struktur des Datastream irrelevant, da der Aufbau des JSONs von einem anderen Lehrstuhl (weiter)entwickelt wird
	\item \textbf{Kostenmodell} \newline
	Das Kostenmodell ist ein Modell, dass einerseits einige Metainformationen sowie die Schritte der Abfrageverarbeitung enthält die bei einer Ausführung berücksichtigt werden, um die Ressourcenkosten zu bewerten. Das Format des Kostenmodells wird vom Lehrstuhl X entwickelt.
	\item \textbf{Geräteigenschaften} \newline
	Geräteeigenschaften definieren, welche Datentypen als auch Operatoren wie z.B. LIKE oder == das Gerät versteht und verwenden kann. Das Format der Geräteeigenschaften wird vom Lehrstuhl X entwickelt.
	\item \textbf{SQL Query und Ausführungsplan} \newline
	Da die Ausführungspläne für Analysezwecke genutzt werden sollen, um im späteren Verlauf Kostenmodelle zu optimieren, muss der Ausführungsplan sowie der SQL Query abgespeichert werden.
\end{itemize}
Weiterhin kann sich eine Übersicht über die Datenbankoperationen der Entitäten geschaffen werden, da diese unterschiedliche genutzt werden.
So wird ein Großteil der Datenbankabfragen und die dazugehörigen Ausführungspläne vom Optimierer zum Query-Repository gesendet. 
Zeitgleich kann jedoch auch eine Datenbankabfrage vom Nutzer formuliert werden, welche dann anschließend erst zum Optimierer weitergeleitet werden muss um den dazugehörigen Ausführungsplan zu erhalten. Während also sowohl Nutzer als auch Maschine Datenbankabfragen in das Query-Repository bringen, werden Ausführungspläne exklusiv nur von einer maschinellen Entität erstellt.

Die Entitäten, die zu den Geräten gehören, hingegen werden nur vom Nutzer erzeugt, müssen jedoch von den anderen Aktoren des System gelesen werden für die Konfiguration. 
Weiterhin kann davon ausgegangen werden, dass die Erstellung von den Geräteentitäten und deren dazugehörigen Relationen wie Eigenschaften und Datenstreams überwiegend während des Aufbaus des Systems geschrieben werden und im laufe der Zeit unter Umständen hin und wieder aktualisiert werden. Die Eigenschaften der Geräte sind dabei evolutionär. Dies bedeutet, dass im laufe der Zeit die Ausführungspläne verändert/verbessert werden, um dann auch spätere Analysen ermöglichen zu können, werden Geräteeigenschaften nicht gelöscht,(TODO eig. ist eine modifizierung wie ein insert, da aus einer modifizierung ein neuer Plan bedeutet) sondern müssen wie eine Verlaufsliste einen Gerät zugeordnet werden können inklusive der Zeiten in denen es genutzt wurden.
Die Tabelle \ref{3:CRUD_Database} zeigt dabei eine Zusammenfassung der unterschiedlichen Operationen und deren vermutlichen Nutzungsstärke.

\begin{table}[ht]
	\centering
	\caption{Initiierte Datenbankoperationen zwischen Maschinen und Nutzern unter Berücksichtigung der voraussichtlichen Zugriffshäufigkeit. TODO Legende: weiß= nicht vorgesehen,Grün=sehr selten,gelb= selten, rot=häufig, }
	\label{3:CRUD_Database}
	\begin{tabular}{|c|c|c|c|c|c|c|}
		\hline
		\multirow{2}{*}{Aktion} & Gerät & Query & Ausführungsplan & Kostenmodell& Eigenschaften & Datenstream \\
		& & & & & &\\
		\hline
		\multirow{2}{*}{Select} & \cellcolor{Yellow}Nutzer& \cellcolor{Red}Nutzer & \cellcolor{Yellow}Nutzer & \cellcolor{Yellow}Nutzer & \cellcolor{Yellow}Nutzer & \cellcolor{Green}Nutzer \\
		%second line
		& Dienst & Dienst & Dienst & \cellcolor{Yellow}Dienst & \cellcolor{Yellow}Dienst &\cellcolor{Yellow}Dienst   \\
		\hline
		\multirow{2}{*}{Insert} & \cellcolor{Yellow}Nutzer & \cellcolor{Red}Nutzer &  Nutzer & \cellcolor{Yellow}Nutzer & \cellcolor{Yellow}Nutzer & \cellcolor{Green}Nutzer \\
		%second line
		& Dienst & \cellcolor{Red}Dienst & \cellcolor{Red}Dienst & Dienst & Dienst & Dienst   \\
		\hline
		\multirow{2}{*}{Modify} & \cellcolor{Yellow}Nutzer & Nutzer & Nutzer & \cellcolor{Yellow}Nutzer & \cellcolor{Yellow}Nutzer & \cellcolor{Green}Nutzer \\
		%second line
		& Dienst& Dienst & Dienst & Dienst & Dienst & Dienst   \\
		\hline
		\multirow{2}{*}{Delete}& Nutzer & Nutzer & Nutzer & Nutzer & Nutzer & Nutzer \\
		%second line
		& Dienst & Dienst & Dienst & Dienst & Dienst & Dienst   \\
		
		\hline
	\end{tabular}
\end{table}
Mittels den zusammengetragenen Informationen kann anschließend abgeleitet werden, dass wenn auch Geräte, Eigenschaften und Datenstream wichtig sind, diese jedoch für die Performance und Konzeption eine geringeren Stellenwert im Hinblick auf der Performance haben, als Query und Ausführungsplan, da diese eben am meisten genutzt werden. Weiterhin zeigt sich auch, dass die Entitäten für ihre Anwendungszwecke getrennt betrachtet werden können, denn Sowohl Query als Ausführungsplan besitzen und brauchen keine Verbindung mit den Informationen zu den Geräteentitöten.
Mit den nun vorhanden Informationen kann gezeigt werden, welche Datenbanktechnologie im Zuge des Query-Repository sinnvoller wäre. 
Für das speichern des Query und den Ausführungsplan würde wahrscheinlich in einer dokumentenorientierten Datenbank sowohl Query als auch Ausführungsplan gespeichert werden. In einer relationalen Datenbank hingegen würde sich wahrscheinlich dazu entschieden werden 2 Tabellen für  Query und Ausführungsplan zu erzeugen und diese mit einem Fremdschlüssel zu verbinden. Oberflächlich zeigt sich hier nur wenig unterschied zwischen den Datenbanktechnologien, wie jedoch später im Konteptionsteils gezeigt wird, kann mit einem relationalen Modell eine gute Optimierung den Speicherplatz betreffend und den selektieren der Daten erreicht werden (todo auf unteres kapitel mit Lösungsvorschlag 3 verweisen). Dies wäre zwar theoretisch auch wieder in einer dokumentenorienteren Datenbank möglich, jedoch wird für die Optimierung ein typischer Zusammenhang zwischen den beiden Relationen erzeugt, sodass der Ansatz auf einer relationalen Datenbank wesentlich intuiver ist und letzlich auch genau für sowas vorgehesen ist.
Bei den Entitäten die den Geräten betreffen wäre der relationale Ansatz für alle der Entitäten eine Tabelle zu erzeugen. Anschließend kann mittels Fremschlüssel und Joins die Informationen wieder zusammengetragen werden. Besonders sei dabei auf den Datenstream hinzuweisen, der im späteren Verlauf mit Ports von Geräten in Relation gesetzt werden muss.
In einer dokumentenorientierte Datenbank hingegen würden wahrscheinlich Geräte als auch das Kostenmodell in einem Schema enthalten sein. Für den Datenstream hingegen müsste ein weiteres Schema erstellt werden, damit ein Datenstream nur einmalig erstellt werden müsste und dann mit einem lookup unterschiedlichen Geräten zigewiesen werden zu können. Im Vergleich bräuchte es in einer relationalen Datenbank mindestens 3 Tabellen während eine dokumentenorientierten Datenbank ebenfalls 2 Schema bräuchte.
Mit der Tatsache, dass besonders Query als auch der dazugehörige Ausführungsplan mittels relationalen Modell stark verbessert werden kann, zeigt sich hier, dass ein relationale Datenbank besser geeignet ist als eine dokumentenorientierte.
TODO anpassen, dass das untere zum oberen passt
Bei den relationalen Datenbanken hingegen existieren zwischen mariaDB, mysql und Postgressql teils nur marginale unterschiede. Ebenfalls zeigen großen Firmen wie Google bei ??? Für mysql und uber bei ??? Für mysql sowie ??? Für Postgressql, dass letzlich mit allen Datenbanken die Anwendung geschrieben werden könnte. Nichtsdestrotztroz wurde sich für Postgressql entschieden. Dabei gab es zwei ausschlaggebende Gründe für die Wahl. Einerseits bietet Postgressql als einzige der drei Datenbanken die Speicherung von JSON in Textformat als auch in Binary Format an. Der Unterschied ist dabei, dass bei der Textspeicherung das JSON die Schlüssel-Wert Paare in der gleichen Reihenfolge bleiben, während dies im JSONB Format nicht garantiert ist. Dieser Unterschied ist wichtig, weil die unterschiedlichen entitäten unterschiedliche Anforderungen besitzen. So ist es für den Kostenplan wichtig, dass die Reihenfolge der Schlüssel-Wert Paare gleich bleiben, da ein Nutzer typischerweise immer die gleiche  Reihenfolge der Schlüssel-Wert Paare wählt und dementsprechend diese dann auch erwartet. Bei dem Ausführungsplan hingegen kann die Reihenfolge der Speicherung egal sein, da diese größtenteils für maschinelles lernen genutzt wird. Inwiefern dann wirklich die jeweiligen Entitäten abgespeichert werden, kann im anfangsstadion noch nicht gesagt werden, weswegen Postgressql hier eine sinnvolle flexibität bietet. Ein weiterer Vorteil den Postgressql bietet im Vergleich zu den beiden anderen ist dabei die Funktionaltiät des Indexen. So ist Postgressql ein indexn möglich ohne die erstellung von virtuellen Zeilen TODO schöner erläutern






\subsection{Query-Ausführungsplan}
Das speichern der Queries als auch des dazugehörigen Ausführungsplans ist eine Aufgabe die das Query Repository erfüllen muss.Für die Modellierung können diese beide Entitäten als erstes getrennt betrachtet werden. Zwar gibt es ebenfalls eine Verbindung zwischen den Ausführungsplan und  beteiligten 



 Diese zwei Relationen können fürs erste 
dabei für die Erstellung des Datenmodells getrennt betrachtet werden.  

getrennt isoliert betrachtet werden, da es keine Abhängigkeiten zu anderen Relationen gibt. Die Informationen, die die Relationen dabei abspeichern müssen sollen hier nun kurz vor der Vorstellung unterschiedlicher Lösungsanätze vorgetstellt werden.
\begin{itemize}
	\item Query\newline Der Query ist eine Datenbankabfrage die entweder vom Nutzer oder vom System kommt. Die Daten die von einem Query abgespeichert werden müssen, ist dabei einmal das \textbf{Query Statement}, der \textbf{genaue Zeitpunkt} als auch der dazugehörige \textbf{Ausführungsplan}.
	\item Ausführungsplan\newline Ein jeder Query besitzt ein Ausführungsplan, der die einzelnen Schritte zur Ausführung des Queries auflistet. Diese werden dann vom Datenbankmanagementsystem gelesen und umgesetzt. Da der Ausführungsplan als ein komplex verschachteltetes JSON vom Optimizer generiert wird, muss hier nur der \textbf{Ausführungsplan als JSON}, der \textbf{genaue Zeitpunkt} als auch der dazugehörige \textbf{Query} abgespeichert werden.
\end{itemize}




\subsubsection{Lösungsvorschlag 1}

Da sowohl der Query als auch der Ausführungsplan mit einem genaue Zeitpunkt abgespeichert werden, wann sie erzeugt bzw. generiert wurden, würde es sich anbieten als Primary Key den 
Zeitpunkt als Primary Key zu nutzen, also einen Timestamp. Das dazugehörige ER-Modell kann dabei in Abbildung X gesehen werden. Auf dem ersten Blick ist ein ganz klarer Vorteil, dass kein künstlicher Schlüssel oder Attribute für die Herstellung der Relation erzeugt werden muss und ebenfalls auch die Anzahl der Attribute der Entitäten sehr gering und damit auch übersichtlich ist.
So einfach wie das Modell umzusetzen ist, bietet es jedoch einige Nachteile:
\begin{enumerate}
	\item Die Portabilität des Systems wird unter Umständen eingeschränkt, da prinzipiell unterschiedliche Datenbanktechnologien eine begrenzte Genauigkeit bei der Speicherung eines Timestamps besitzen. So ermöglicht Postgresql Beispielsweise eine maximale Speicherung eines Timestamps in Mikrosekunden\footnote{https://www.postgresql.org/docs/7.3/datatype-datetime.html}
	\item Aufbauen auf der Argumentation mit der Portabilität wird prinzipiell auch eine obere Schrank an maximalen Inserts pro Sekunde eingeführt und damit die Skalierbarkeit des Systems künstlich beschränkt. Im falle von PostgreSql wären theoretisch maximal 1 Millionen Insert Operation die Sekunde möglich.
	\item Die mögliche Skalierbarkeit der Anwendung wird für die Zukunft ebenfalls auf ein weiteren Ebene beschränkt. Denn durch die Nutzung eines Timestamps muss ebenfalls davon abgesehen werden eine weitere Instanz des Objekts zu erzeugen welches für die Timestamp erstellung zuständig ist, da dadurch sonst keine Gewährleistung der Einzigartigkeit der Timestamps mehr möglich ist.
	\item Abgesehen von der Timestamp Problematik ist das aktuelle Modell ebenfalls sehr ineffizient, da das Zusammensetzen und Filterung der Daten zur Laufzeit passieren muss, denn aktuell wäre es zwar möglich auf einfacher Weise den Ausführungsplan zu einem Query zu bekommen, jedoch wäre es nicht effizient möglich, zu einem Query jeden bzw. alle einzigartigen Ausführungspläne zurückzugeben.
	\item Durch die Speicherung und Nutzung des Timestamps als Primärschlüssel und Fremdschlüssel entsteht eine hohe Menge an Redundanz, denn sowohl Query als auch Ausführungsplan würden stets abgespeichert werden, auch wenn absehbar ist, das Ausführungspläne sich nur selten ändern und wahrscheinlich häufig gleiche Queries ausgeführt werden. 
\end{enumerate}

\begin{figure}
	\centering
	\includegraphics[width=0.7\linewidth]{"../../OneDrive/masterarbeit/ER diagramm/query_executionplan1.png"}
	\caption{}
	\label{fig:devicefeaturetimestamp1solution}
\end{figure}





\subsubsection{Lösungsvorschlag 2}

TODO hier auf folgendes eingehen:
Mit dieser Lösung kann im ersten Schritt die menge an zu speichernden Queries klein gehalten werden, da vorraussichtlich ja die Menge unterschiedlicher Queries sehr beschränkt sein wird. Um anschließend die Anzahl an nötiger Einträge noch kleiner zu halten, kann die zwischen Entität Execution Plan Hash eingeführt werden. Diese enthält dann das JSON und Execution Plan lediglich eine Referenz zu diesem. Vorteil ist, dass die Redudanz auf ein absolutes minimum reduziert wurde. Problem ist aber eben eine weitere Entität und noch wichtiger: Auf kosten der reduzierung der Redundanz wird die Logik und das rausgeben alle execution plans umständlicher, weil es 2 joins braucht.
reduzierung von Redudanz perfekt, Performance laufzeit aufgrund von 2 joins schlecht
TODO: wäre es auch möglich andersrum zu machen?
sql timestamp  / Sql und dann execution plan?
aber join wäre trotzdem nötig

\begin{figure}[h]
	\centering
	\includegraphics[width=0.7\linewidth]{"../../OneDrive/masterarbeit/ER diagramm/query_executionplan2.png"}
	  \caption{2.2..}
	\label{fig:devicefeaturesolution22}
\end{figure}


\begin{figure}[h]
	\centering
	\includegraphics[width=0.7\linewidth]{"../../OneDrive/masterarbeit/ER diagramm/query_executionplan2_2.png"}
	  \caption{2..}

	\label{fig:devicefeaturehash2solution}
\end{figure}





\subsubsection{Lösungsvorschlag 3}
Bei dem Vorschlag wird sich vom wissen her bedient, das execution plans sich nicht so oft ändern, sprich auch hier wird nur einmal der execution plan gespeichert. Wichtig ist hier, dass auf die 3 Normalform sozusagen verzichtet wurde mit der BEgründung, dass es zwar gleiche Entitäten sind, aber das hier einen Verlauf darstellt (deswegen auch id als PK). Auch wenn die Lösung mehr Speicherplatz verbraucht, ist der große Vorteil dabei, dass es beim frontend performance mäßig sehr einfach ist nach Datumintervallen zu filtern und letzlich auch das speichern der Einträge eine natürlich Reihenfolge darstellt.
Dies kann man als wichtiger bezeichnen, als die paar kb die ein Query braucht.

Wichtig ist auch zu erwähnen, dass ja letzlich für den Nutzer erstmal nur die Datenbankabfragen wichtig sind(ggf. auf frontend frontend hinweisen, da ja smart gelöst mit die werden nachgeladen)

\begin{figure}[h]
	\centering
	\includegraphics[width=0.7\linewidth]{"../../OneDrive/masterarbeit/ER diagramm/query_executionplan3.png"}
	\caption{}
	\label{fig:devicefeaturesolution3}
\end{figure}

\subsubsection{Entscheidung}
Hier kurz zusammenfassen und nochmal sagen warum man Lösungsvorschlag 3 nutzt


\subsection{Device-Capabilities-Datastream}
hier darauf eingehen, das Port eine wichtige Rolle einnimmt, da ein Gerät viele unterschiedliche Ports haben soll. Der Rest der relationen ist ja relativ einfach ggf. aber auch näher auf Geräteeigenschaften eingehen.
Wichtig ist auch zu erwähnen, dass man für device keine ID nimmt sondern den namen als PK. Damit begründen, dass die Anzahl an Geräten ja relativ überschaubar ist und doppelte Namen kein Sinn machen würden.
Bei Port dann zusammengesetzter PK mit devicename und portnumber

\subsubsection{Lösungsvorschlag 1}
Hier ist Port nur eine Entität und besitzt ein enum für Application Port oder Datastream port. Damit begründen, dass ja theoretisch nicht absehrgbar ist, dass neue hinzukommen und damit die speicherung einfacher ist


\subsubsection{Lösungsvorschlag 2}
Hier hat man eine superklasse (Port) und die anderen Erben davon (Datastreamport) und ApplicationPort. Schönste Lösungen bis dato, weil einfach erweiterbar 

\subsubsection{Entscheidung}
Lösungsvorschlag 2, weil er ordentlicher und besser erweiterbar ist (open closed z.B. erwähnen). GGF aber noch nach einer dritten sinnvollen und möglichen Lösung suchen.



\section{Frontend}
kurz vorstellen, dass in dem Kapitel die Oberfläche, die Kommunikationsart als auch Struktur vorgestellt wird.


\subsection{Analyse und Technologieauswahl für das Frontend}
Aufgeteilt in:

Design:
Kurz erläutern, welches Design tools es gibt für das konzipieren des frontends.
1. UML WAE, aber hier darauf hinweisen, dass laut studie das nicht viel bringt (siehe one note 18.08)
Dann kurz die Begriffe wireframe, mockup und Prototyp vorstellen.
Anschließend eben sagen, dass sich wireframes am besten eignet, da das große Ziel ist, die Oberfläche so zu designen, dass im späteren Verlauf wiederverwendbar Komponente darauf hin für angular entworfen werden können

2. Angular vorstellen, stand ja letztlich schon fest

3. Kommunikation arten fürs frontend vergleichen:
REST mit HTTP vs gRPC --> Entscheidung for rest + http wegen bekanntheit und daher auch einfach zu verwenden

Angular mit websocket/ Angular mit http und REST
Polling
Server Side events

\subsection{Benutzeroberfläche}
Beschreiben der jeweiligen Benutzeroberflächen

\subsubsection{Query-Execution}
TODO, moqups abo nötig zum exportieren
Hier darauf eingehen, dass der Ausführungsplan später geladen wird, da ja der Umweg von query-repo --> gateway --> optimizer --> query-repo gegangen wird

\subsubsection{Query-History}
TODO, moqups abo nötig zum exportieren
hier darauf eingehen, dass es möglich sein wird nach Zeit zu suchen und ebenfalls nach bestimmten sql abfragen

\subsubsection{Device-Konfiguration}
TODO, moqups abo nötig zum exportieren
Hier darauf eingehen, dass die Tabelle etwas anders ist im Vergleich zu Query-Execution: Die Spalten des Geräts und Ports sind fest und die zusätzlichen der subport klassen sind scrollable, für einheitliche länge der Tabellen wird das gemacht

\subsection{Frontend Aufbau}

\subsubsection{Logische Sicht}
Auf die Benutzeroberfläche eingehen und die Komponenten konstruieren für das frontend sowie service + modell. 
Erstmal die Gemeinsamkeiten beschreiben und darauf eingehen, dass diese absichtlich gewählt wurden. Sprich:
Tabelle kann als Komponente implementiert werden sowie die dazugehörigen Actions. Die Komponenten nutzen dann die Tabelle und beschreiben ihre Actions.

\subsubsection{Query-History}
\subsubsection{Query-Execution}
\subsubsection{Device-Configuration}


\subsubsection{Laufzeitschicht}
\subsubsection{Query-History}
\subsubsection{Query-Execution}
\subsubsection{Device-Configuration}


\section{Backend}

\subsection{Analyse und Technologieauswahl für das Backend}
auf jeden Fall darauf eingehen, dass sich eig. REST anbietet, da es ja im frontend genutzt wird. Nachteile ist aber das unschönere debugging (auf broker kann ja nachgeschaut werden ob Nachrichten gesendet wurden) und ganz wichtig synchron, wenn einer der Komponenten abschmiert, sind die informationen verloren. Dritter Vorteil ist auch, dass sich nicht über den emfpang gedanken gemacht werdend muss, da dies die genutzte Lib ermöglicht


\subsection{REST-Schnittstelle}
Hier auf die 2  Papers eingehen wie REST- Schnittstellen via Diagramm beschrieben werden können. Dann aber eben argumentieren, dass das ändern und die Pflege intensiver sind ohne ein richtigen Nutzen zu bieten --> deswegen openAPI vorstellen sowie die Generierung des Codes die für das frontend und backend dann möglich sind. Ggf. hier dann die yaml files zeigen.

\subsection{Rabbit MQ}
Teilt sich auf in einmal die geschriebene Lib die nötig ist damit die Systeme untereinander alle die gleiche Sprache sprechen und es eine einfach Schnittstelle für alle gibt. Anschließend das Queue Diagramm vorstellen und beschrieben wie der Nachrichtenfluss ist

\subsubsection{Third Party Library}
erläutern warum eine third party Library sinn macht und aufbau im Kontext von Rabbit MQ erläutern

\subsubsection{Queue Aufbau}
Erläutern welche Verbindungen alle existieren und mit Diagramm zeigen wie diese untereinander verbunden sind.

\subsection{Backend Aufbau}
Erklären, dass das Programm in Spring geschrieben wird.
Anschließend den typische Spring aufbau erläutern:
1. Controller --> hier darauf eingehen, dass das DelegatePattern verwendet wird
1.1 ebenfalls darauf eingehen, dass das DTO genutzt wird für Geräte, da mehrere Tabelle es nutzen.
2.Service --> Service und die Funktionen vorstellen 
3. Repository sowie die Funktionen vorstellen



\subsubsection{Logische Sicht}
\subsubsection{Query-History}
\subsubsection{Query-Execution}
\subsubsection{Device-Configuration}


\subsubsection{Laufzeit Sicht}

\subsubsection{Query-History}
\subsubsection{Query-Execution}
\subsubsection{Device-Configuration}



